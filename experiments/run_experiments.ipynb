{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that you have build the search module\n",
    "import sys\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "\n",
    "import subprocess\n",
    "import json\n",
    "import gzip\n",
    "import os\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean\n",
    "from matplotlib import transforms\n",
    "from matplotlib import colormaps as cm\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../generation\"))\n",
    "import generate\n",
    "from parseRePEAT import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results to a file specified for all different scenarios/layouts\n",
    "with open(\"results/results_2024-03-20_3.csv\", \"w\") as f:\n",
    "    scenarios = {\n",
    "        \"enkhuizen\": {\n",
    "            \"small\": \"../data/enkhuizen/scenario_small_custom.json\", \n",
    "            \"medium\": \"../data/enkhuizen/scenario_reallife_enkhuizen.json\",\n",
    "            \"large\": \"../data/enkhuizen/scenario_n25_t8_w1000_s1234567890.json\", \n",
    "        },\n",
    "        \"heerlen\": {\n",
    "            \"small\": \"../data/heerlen/scenario_n6_t8_w1000_s1234567890.json\",\n",
    "            \"medium\": \"../data/heerlen/scenario_n13_t8_w1000_s1234567890.json\",\n",
    "            \"large\": \"../data/heerlen/scenario_n25_t8_w1000_s1234567890.json\",\n",
    "            \"extralarge\": \"../data/heerlen/scenario_n50_t8_w1000_s1234567890.json\",\n",
    "        }\n",
    "    }\n",
    "    layouts = {\"enkhuizen\": \"../data/enkhuizen/location_enkhuizen.json\", \"heerlen\": \"../data/heerlen/location_heerlen.json\"}\n",
    "    f.write(\"Layout,Scenario,Agent,Start,Goal,StartTime,ScenarioTime,NodeIntervals,EdgeIntervals,GenTime,SearchTime,LookupTime,Path,PathLength,PathUsed,PathOccurrence,PathTraversalTime,PathSafeIntervals,SippSearch,SippLookup\\n\")\n",
    "    for layout in scenarios:\n",
    "        for scen in scenarios[layout]:\n",
    "            scenario_data = json.load(open(scenarios[layout][scen]))\n",
    "            train_types = {x[\"name\"]: x for x in scenario_data[\"types\"]}\n",
    "            # Iteratively assign one of the trains to be the agent\n",
    "            for agent in scenario_data['trains']:\n",
    "                # Get the global end time of scenario\n",
    "                scenario_end_time = 0\n",
    "                for i in range(len(agent[\"movements\"])):\n",
    "                    move = agent[\"movements\"][i]\n",
    "                    if move[\"endTime\"] > scenario_end_time:\n",
    "                        scenario_end_time = move[\"endTime\"]\n",
    "                agent_speed = train_types[agent[\"trainUnitTypes\"][0]][\"speed\"]\n",
    "                print(f\"Computing results for agent {agent['trainNumber']} in scenario {scen} on layout {layout}\")\n",
    "                for move in agent[\"movements\"]:\n",
    "                    # Generate intervals\n",
    "                    generation_time = generate.time_safe_intervals_and_write(layouts[layout], scenarios[layout][scen], agent[\"trainNumber\"], agent_speed, \"output\")\n",
    "                    safe_interval_output = [str(x).split(\"'\")[1] for x in gzip.open(\"output\").readlines()]\n",
    "\n",
    "                    # Run SIPP baseline\n",
    "                    try:\n",
    "                        proc = subprocess.run([\"../search/build/atsipp\", \"--start\", move[\"startLocation\"], \"--goal\", move[\"endLocation\"], \"--edgegraph\", \"output\", \"--search\", \"sipp\", \"--startTime\", str(move[\"startTime\"]), \"--agentSpeed\", str(agent_speed), \"--walkingSpeed\", str(scenario_data[\"walkingSpeed\"])], timeout=300, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL)\n",
    "                    except subprocess.TimeoutExpired:\n",
    "                        print(f'Timeout for sipp (300s) expired')\n",
    "                    sipp_output = str(proc.stdout).split(\"'\")[1].strip(\"\\\\n\").split(\"\\\\n\")\n",
    "                    # SIPP results\n",
    "                    if int(proc.returncode) == 0:\n",
    "                        sipp_search_time = [float(x.split(\" \")[2]) for x in sipp_output if \"Search time\" in x][0]\n",
    "                        # SIPP lookup is instant and set to 1 nanosecond\n",
    "                        sipp_lookup_time = 1 \n",
    "\n",
    "                    # Run RePeAT to get multiple plans\n",
    "                    try:\n",
    "                        proc = subprocess.run([\"../search/build/atsipp\", \"--start\", move[\"startLocation\"], \"--goal\", move[\"endLocation\"], \"--edgegraph\", \"output\", \"--search\", \"repeat\", \"--startTime\", str(move[\"startTime\"]), \"--agentSpeed\", str(agent_speed), \"--walkingSpeed\", str(scenario_data[\"walkingSpeed\"])], timeout=300, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL)\n",
    "                    except subprocess.TimeoutExpired:\n",
    "                        print(f'Timeout for repeat (300s) expired')                            \n",
    "                    repeat_output = str(proc.stdout).split(\"'\")[1].strip(\"\\\\n\").split(\"\\\\n\")\n",
    "                    try: \n",
    "                        all_lookups = [(int(x.split(\" \")[1].strip(\")\").split(\"=\")[1]), float(x.split(\" \")[4])) for x in repeat_output if \"Lookup time\" in x]\n",
    "                        # Divide by number of lookups provided: Total (n=<x>) Lookup time: <y> nanoseconds\n",
    "                        lookup_time = mean([y / x for x, y in all_lookups])\n",
    "                    except: lookup_time = np.nan\n",
    "\n",
    "                    # If the run was successful\n",
    "                    if int(proc.returncode) == 0:\n",
    "                        search_time = [float(x.split(\" \")[2]) for x in repeat_output if \"Search time\" in x][0]\n",
    "                        metadata, catf, paths, eatfs = parse_list_of_outputs(repeat_output)\n",
    "                        total_paths_found = sum([paths[p] for p in paths])\n",
    "                        for path_name in paths:\n",
    "                            # The ratio of how often this path was found\n",
    "                            occurrence = paths[path_name] / total_paths_found\n",
    "                            path_length = len(path_name.split(\";\"))\n",
    "                            path_traversal = eatfs[path_name][0][3] # traversal is same no matter the start time\n",
    "                            # Get the different safe intervals (start, end) for traversing the current path\n",
    "                            path_eatfs = \";\".join([f\"<{float(e[1])}-{float(e[2])}>\" for e in eatfs[path_name]])\n",
    "                            f.write(f\"{layout},{scen},{str(agent['trainNumber'])},{move['startLocation']},{move['endLocation']},{move['startTime']},<{0}-{scenario_end_time}>,{safe_interval_output[0][0:-2].split(' ')[-1]},{sum([1 for x in safe_interval_output if len(x.split(' ')) == 6])},{generation_time},{'{0:.9f}'.format(search_time*10**-9)},{'{0:.9f}'.format(lookup_time*10**-9)},[{path_name}],{path_length},{paths[path_name]},{occurrence},{path_traversal},{path_eatfs},{'{0:.9f}'.format(sipp_search_time*10**-9)},{'{0:.9f}'.format(sipp_lookup_time*10**-9)}\\n\")\n",
    "                    else:\n",
    "                        f.write(f\"{layout},{scen},{str(agent['trainNumber'])},{move['startLocation']},{move['endLocation']},{move['startTime']},<{0}-{scenario_end_time}>,{safe_interval_output[0][0:-2].split(' ')[-1]},{sum([1 for x in safe_interval_output if len(x.split(' ')) == 6])},{generation_time},{np.nan},{'{0:.9f}'.format(lookup_time*10**-9)},[],0,{np.nan},{np.nan},0,[()],0,0\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data for the graph compilations\n",
    "df = pd.read_csv('results/results_2024-03-20_1.csv')\n",
    "# To show what the data looks like\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig8 - @MAEDeR and rSIPP milestones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper object for legend with subtitles\n",
    "import matplotlib.text as mtext\n",
    "\n",
    "class LegendTitle(object):\n",
    "    def __init__(self, text_props=None):\n",
    "        self.text_props = text_props or {}\n",
    "        super(LegendTitle, self).__init__()\n",
    "\n",
    "    def legend_artist(self, legend, orig_handle, fontsize, handlebox):\n",
    "        x0, y0 = handlebox.xdescent, handlebox.ydescent\n",
    "        title = mtext.Text(x0, y0, orig_handle,  **self.text_props)\n",
    "        handlebox.add_artist(title)\n",
    "        return title\n",
    "    \n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# Function to format tick labels\n",
    "def format_tick(value, tick_number):\n",
    "    return f'10^{tick_number}'\n",
    "log_formatter = FuncFormatter(format_tick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating stack barplot of different milestones with medium enkhuizen and extralarge heerlen scenarios\n",
    "scenarios = 2\n",
    "nan = np.nan\n",
    "\n",
    "newdf = df.query('PathUsed != @nan and (Layout == \"enkhuizen\" and Scenario == \"medium\") or (Layout == \"heerlen\" and Scenario == \"extralarge\")')\n",
    "asipp = newdf\n",
    "\n",
    "sipp = newdf\n",
    "sipp['Query'] = newdf['SippSearch'] + newdf['SippLookup']\n",
    "sipp['Recompute'] = newdf['SippSearch'] + newdf['GenTime']\n",
    "\n",
    "fig = plt.figure(figsize=(3*scenarios, 8))\n",
    "ax = fig.add_subplot()\n",
    "bar_width = 0.35\n",
    "fontsize = 14\n",
    "# print(df.query('(Layout == \"heerlen\" and Scenario == \"medium\")').head(100))\n",
    "\n",
    "\n",
    "colors = {\n",
    "    \"SIPP\": {\n",
    "        \"Bar1\": '#f6e8c3',\n",
    "        \"Bar2\": '#d8b365',\n",
    "        \"Bar3\": \"#8c510a\",\n",
    "        \"Line\": '#573206'\n",
    "    },\n",
    "    \"@SIPP\": {\n",
    "        \"Bar1\": \"#c7eae5\",\n",
    "        \"Bar2\": '#5ab4ac',\n",
    "        \"Bar3\": '#01665e',\n",
    "        \"Line\": '#02554d'\n",
    "    }\n",
    "}\n",
    "errors = {\n",
    "    \"Bar1\": {\n",
    "        \"ecolor\": 'black',\n",
    "        \"fmt\": 'ks',\n",
    "        \"transform\": transforms.Affine2D().translate(-0.1, 0.0) + ax.transData\n",
    "    },\n",
    "    \"Bar2\": {\n",
    "        \"ecolor\": 'gray',\n",
    "        \"fmt\": 'k^',\n",
    "        \"transform\": transforms.Affine2D().translate(0, 0.0) + ax.transData\n",
    "    },\n",
    "    \"Bar3\": {\n",
    "        \"ecolor\": 'gray',\n",
    "        \"fmt\": 'ko',\n",
    "        \"transform\": transforms.Affine2D().translate(+0.1, 0.0) + ax.transData\n",
    "    }\n",
    "}\n",
    "layouts = [\n",
    "    \"Enkhuizen\",\n",
    "    \"Heerlen\"\n",
    "]\n",
    "\n",
    "## @SIPP\n",
    "\n",
    "positions_asipp = [0, 1]\n",
    "positions_sipp = [0+bar_width, 1+bar_width]\n",
    "\n",
    "plot_first = 1\n",
    "plot_second = 0\n",
    "\n",
    "### Lookup time: querying the safe plan\n",
    "lookups = np.array(asipp.groupby('Scenario')['LookupTime'].mean().sort_index(ascending=False))\n",
    "asipp_lookup = ax.bar(positions_asipp, lookups, label=\"Solve: Query plan\", bottom=0, color=colors[\"@SIPP\"][\"Bar1\"], width=bar_width)\n",
    "asipp_line = ax.axhline(lookups[plot_first], color=colors[\"@SIPP\"][\"Line\"], xmin=0, xmax=1, linewidth=2, dashes=(1, 3))\n",
    "ax.annotate('{:.2e}'.format(lookups[plot_first]), xy=(0, lookups[plot_first]), xytext=(-0.3, lookups[plot_first]), va='bottom', ha='right')\n",
    "ax.annotate(\"@MAEDeR: Safe\", xy=(1, lookups[plot_first]), xytext=(1.65, lookups[plot_first]), va='top', color=colors[\"@SIPP\"][\"Line\"])\n",
    "if plot_second >= 0:\n",
    "    ax.axhline(lookups[plot_second], color=colors[\"@SIPP\"][\"Line\"], xmin=0, xmax=1, linewidth=2, dashes=(1, 3))\n",
    "    ax.annotate('{:.2e}'.format(lookups[plot_second]), xy=(0, lookups[plot_second]), xytext=(-0.3, lookups[plot_second]), va='top', ha='right')\n",
    "\n",
    "### Generation time: recomputing SIPP graphs other agents\n",
    "graphs = np.array(asipp.groupby(['Scenario', 'Agent']).sum('GenTime').groupby('Scenario')['GenTime'].mean().sort_index(ascending=False))\n",
    "asipp_graphs = ax.bar(positions_asipp, graphs, label=\"Recompute SIPP graphs\", bottom=lookups, color=colors[\"@SIPP\"][\"Bar2\"], width=bar_width)\n",
    "height = lookups + graphs\n",
    "ax.axhline(height[plot_first], color=colors[\"@SIPP\"][\"Line\"], xmin=0, xmax=1, linewidth=2, dashes=(1, 3))\n",
    "ax.annotate('{:.2f}'.format(height[plot_first]), xy=(0, height[plot_first]), xytext=(-0.3, height[plot_first]), va='top', ha='right')\n",
    "ax.annotate(\"rSIPP: Recovered &\\n@MAEDeR: Partial\", xy=(1, height[plot_first]), xytext=(1.65, height[plot_first]), va='top')\n",
    "if plot_second >= 0:\n",
    "    ax.axhline(height[plot_second], color=colors[\"@SIPP\"][\"Line\"], xmin=0, xmax=1, linewidth=2, dashes=(1, 3))\n",
    "    ax.annotate('{:.2f}'.format(height[plot_second]), xy=(0, height[plot_second]), xytext=(-0.3, height[plot_second]), va='top', ha='right')\n",
    "    ax.annotate(\"rSIPP: Recovered &\\n@MAEDeR: Partial\", xy=(1, height[plot_second]), xytext=(1.65, height[plot_second]),  va='top')\n",
    "\n",
    "### Search time: recomputing any-start-time plans for other agents\n",
    "others = np.array(asipp.groupby(['Scenario', 'Agent']).sum('SearchTime').groupby('Scenario')['SearchTime'].mean().sort_index(ascending=False))\n",
    "height = lookups + graphs + others\n",
    "asipp_recompute = ax.bar(positions_asipp, others, label=\"Replan in advance\", bottom=lookups + graphs, color=colors[\"@SIPP\"][\"Bar3\"], width=bar_width)\n",
    "ax.axhline(height[plot_first], color=colors[\"@SIPP\"][\"Line\"], xmin=0, xmax=1, linewidth=2, dashes=(1, 3))\n",
    "ax.annotate('{:.2f}'.format(height[plot_first]), xy=(0, height[plot_first]), xytext=(-0.3, height[plot_first]), va='bottom', ha='right')\n",
    "ax.annotate(\"@MAEDeR: Recovered\", xy=(1, height[plot_first]), xytext=(1.65, height[plot_first]), va='baseline', color=colors[\"@SIPP\"][\"Line\"])\n",
    "if plot_second >= 0:\n",
    "    ax.axhline(height[plot_second], color=colors[\"@SIPP\"][\"Line\"], xmin=0, xmax=1, linewidth=2, dashes=(1, 3))\n",
    "    ax.annotate('{:.2f}'.format(height[plot_second]), xy=(0, height[plot_second]), xytext=(-0.3, height[plot_second]), va='bottom', ha='right')\n",
    "    ax.annotate(\"@MAEDeR: Recovered\", xy=(1, height[plot_second]), xytext=(1.65, height[plot_second]), va='baseline', color=colors[\"@SIPP\"][\"Line\"])\n",
    "\n",
    "# SIPP\n",
    "### Search time: querying the plan: cpp search time + lookup time\n",
    "query = np.array(sipp.groupby('Scenario')['Query'].mean().sort_index(ascending=False))\n",
    "sipp_query = ax.bar(positions_sipp, query, label=\"Solve: Search plan\", bottom=0, color=colors[\"SIPP\"][\"Bar1\"], width=bar_width)\n",
    "sipp_line = ax.axhline(query[plot_first], color=colors[\"SIPP\"][\"Line\"], xmin=0, xmax=1, linewidth=2, dashes=(3, 4))\n",
    "ax.annotate('{:.2e}'.format(query[plot_first]), xy=(0, query[plot_first]), xytext=(-0.3, query[plot_first]), va='center', ha='right')\n",
    "ax.annotate(\"rSIPP: Safe\", xy=(1, query[plot_first]), xytext=(1.65, query[plot_first]), va='top', color=colors[\"SIPP\"][\"Line\"])\n",
    "if plot_second >= 0:\n",
    "    ax.axhline(query[plot_second], color=colors[\"SIPP\"][\"Line\"], xmin=0, xmax=1, linewidth=2, dashes=(3, 4))\n",
    "    ax.annotate('{:.2e}'.format(query[plot_second]), xy=(0, query[plot_second]), xytext=(-0.3, query[plot_second]), va='center', ha='right')\n",
    "    ax.annotate(\"rSIPP: Safe\", xy=(1, query[plot_second]), xytext=(1.65, query[plot_second]), va='center', color=colors[\"SIPP\"][\"Line\"])\n",
    "\n",
    "### Recompute time: summing generation + search time for all other agents\n",
    "recomputes = np.array(sipp.groupby(['Scenario', 'Agent']).sum('GenTime').groupby('Scenario')['GenTime'].mean().sort_index(ascending=False))\n",
    "sipp_recompute = ax.bar(positions_sipp, recomputes, label=\"Recompute SIPP graphs\", bottom=query, color=colors[\"SIPP\"][\"Bar2\"], width=bar_width)\n",
    "ax.axhline(recomputes[plot_first], color=colors[\"SIPP\"][\"Line\"], xmin=0, xmax=1, linewidth=2, dashes=(3, 4))\n",
    "# Text in rSIPP recompute box, to match the @MAEDeR Recompute\n",
    "# Make sure this is positioned without lines crossing it\n",
    "ax.annotate('{:.3f}s'.format(recomputes[plot_first]), xy=(0.1, query[plot_first]), xytext=(positions_sipp[plot_first], query[plot_first]), ha='center', va='bottom')\n",
    "# The MAEDeR value - position at same height\n",
    "ax.annotate('{:.3f}s          '.format(graphs[plot_first]), xy=(0.1, query[plot_first]), xytext=(positions_asipp[plot_first], query[plot_first]), ha='center', va='top', rotation='vertical')\n",
    "if plot_second >= 0:\n",
    "    ax.axhline(recomputes[plot_second], color=colors[\"SIPP\"][\"Line\"], xmin=0, xmax=1, linewidth=2, dashes=(3, 4))\n",
    "    # Text in rSIPP recompute box, to match the @MAEDeR Recompute\n",
    "    # Make sure this is positioned without lines crossing it\n",
    "    ax.annotate('{:.3f}s'.format(recomputes[plot_second]), xy=(0.1, query[plot_second]), xytext=(positions_sipp[plot_second], query[plot_second]), ha='center', va='bottom')\n",
    "    # The MAEDeR value - position at same height\n",
    "    ax.annotate('{:.3f}s    '.format(graphs[plot_second]), xy=(0.1, query[plot_second]), xytext=(positions_asipp[plot_second], query[plot_second]), ha='center', va='top', rotation='vertical')\n",
    "\n",
    "\n",
    "## Recompute SIPP graph time for both\n",
    "print(f\"@MAEDeR recompute SIPP graph\", graphs)\n",
    "print(f\"rSIPP recompute SIPP graph\", recomputes)\n",
    "\n",
    "ax.annotate(\"MAEDeR problem\\nmilestones\", xy=(1.6, 1.6), xytext=(1.65,1.5), weight='bold')\n",
    "ax.set_xticks(np.arange(scenarios) + (len(layouts)) * bar_width / 4)\n",
    "ax.set_xticklabels([\"Real-world scenario\\nEnkhuizen (13 trains)\", \"Extra large scenario\\nHeerlen (50 trains)\"])\n",
    "ax.set_xlabel(\"Scenario size\", weight='bold')\n",
    "ax.set_yticks([])\n",
    "ax.set_yscale(\"log\")\n",
    "min_exponent = np.floor(np.log10(np.abs(min(newdf.query('LookupTime > 0')['LookupTime']))))\n",
    "ax.set_ylim(10**(min_exponent), 5)\n",
    "ax.set_ylabel(\"Time (s)\\n(logarithmic\\nscale)\", rotation='horizontal', ha='right', weight='bold')\n",
    "ax.yaxis.set_major_formatter(matplotlib.ticker.NullFormatter())\n",
    "ax.yaxis.set_minor_formatter(matplotlib.ticker.NullFormatter())\n",
    "ax.legend([\"@MAEDeR sequence\", asipp_line, asipp_lookup, asipp_graphs, asipp_recompute, \"rSIPP sequence\", sipp_line, sipp_query, sipp_recompute],\n",
    "          [\"\", \"@MAEDeR milestone\", asipp_lookup.get_label(), asipp_graphs.get_label(), asipp_recompute.get_label(), \"\", \"rSIPP milestone\", sipp_query.get_label(), sipp_recompute.get_label()],\n",
    "          handler_map={str: LegendTitle({'fontsize': fontsize})},\n",
    "          loc=(0,-0.35),\n",
    "          ncol=2)\n",
    "ax.xaxis.set_label_coords(1.2, -0.02)\n",
    "ax.yaxis.set_label_coords(-0.01, 0.90)\n",
    "ax.set_title(\"Comparing @MAEDeR and rSIPP\")\n",
    "\n",
    "plt.rcParams.update({'font.size': fontsize})\n",
    "plt.savefig(\"results/sipp_vs_asipp_dpi300.png\",\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "            format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Fig9 - runtime per layout and scenario: safe + unsafe intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot runtime both methods for all layouts and scenarios - sorted per scenario and layout\n",
    "nan = np.nan\n",
    "newdf = df.query('PathUsed != @nan').groupby(['Scenario', 'Layout'])\n",
    "\n",
    "means = {\n",
    "    \"rSIPP\": {\n",
    "        \"Generation time\": np.array(newdf['GenTime'].mean().sort_values(ascending=True).unstack(level=0).sort_index(axis=1, ascending=False)),\n",
    "        \"Search time\": np.array(newdf['SippSearch'].mean().sort_values(ascending=True).unstack(level=0).sort_index(axis=1, ascending=False)),\n",
    "    },\n",
    "    \"@MAEDeR\": {\n",
    "        \"Generation time\": np.array(newdf['GenTime'].mean().sort_values(ascending=True).unstack(level=0).sort_index(axis=1, ascending=False)),\n",
    "        \"Search time\": np.array(newdf['SearchTime'].mean().sort_values(ascending=True).unstack(level=0).sort_index(axis=1, ascending=False)),\n",
    "    }\n",
    "}\n",
    "stds = {\n",
    "    \"rSIPP\": {\n",
    "        \"Search time\": np.array(newdf['SippSearch'].std().sort_values(ascending=True).unstack(level=0).sort_index(axis=1, ascending=False)),\n",
    "        \"Generation time\": np.array(newdf['GenTime'].std().sort_values(ascending=True).unstack(level=0).sort_index(axis=1, ascending=False)),\n",
    "    },\n",
    "    \"@MAEDeR\": {\n",
    "        \"Search time\": np.array(newdf['SearchTime'].std().sort_values(ascending=True).unstack(level=0).sort_index(axis=1, ascending=False)),\n",
    "        \"Generation time\": np.array(newdf['GenTime'].std().sort_values(ascending=True).unstack(level=0).sort_index(axis=1, ascending=False)),\n",
    "    }\n",
    "}\n",
    "labels = {\n",
    "    \"small\": \"6 trains\",\n",
    "    \"medium\": \"13 trains\",\n",
    "    \"large\": \"25 trains\",\n",
    "    \"extralarge\": \"50 trains\"\n",
    "}\n",
    "layouts = [\n",
    "    \"Enkhuizen\",\n",
    "    \"Heerlen\"\n",
    "]\n",
    "search = [\n",
    "    \"@MAEDeR\",\n",
    "    \"rSIPP\"\n",
    "]\n",
    "legend = {\n",
    "    \"rSIPP\": {\n",
    "        \"Search time\": \"Search for plan\",\n",
    "        \"Generation time\": \"Recompute SIPP graph\",\n",
    "    },\n",
    "    \"@MAEDeR\": {\n",
    "        \"Search time\": \"Search for plan\",\n",
    "        \"Generation time\": \"Recompute @SIPP graph\",        \n",
    "    }\n",
    "}\n",
    "colors = {\n",
    "    \"@MAEDeR\": {\n",
    "        \"Generation time\": '#e66101',\n",
    "        \"Search time\": '#fdb863'\n",
    "    },\n",
    "    \"rSIPP\": {\n",
    "        \"Generation time\": \"#5e3c99\",\n",
    "        \"Search time\": '#b2abd2',\n",
    "    }\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "errors = {\n",
    "    \"Generation time\": {\n",
    "        \"ecolor\": 'black',\n",
    "        \"fmt\": 'ks',\n",
    "        \"transform\": transforms.Affine2D().translate(-0.03, 0.0) + ax.transData\n",
    "    },\n",
    "    \"Search time\": {\n",
    "        \"ecolor\": 'black',\n",
    "        \"fmt\": 'ko',\n",
    "        \"transform\": transforms.Affine2D().translate(+0.03, 0.0) + ax.transData\n",
    "    }\n",
    "}\n",
    "\n",
    "bar_width = 0.1\n",
    "legends = {}\n",
    "for i, l in enumerate(layouts):\n",
    "    for k, s in enumerate(search):\n",
    "        bottom = np.zeros(len(labels))\n",
    "        for name, x in means[s].items():\n",
    "            positions = i + np.arange(len(labels.values()))*2.5*bar_width + k*bar_width\n",
    "            p = ax.bar(positions, x[i], label=legend[s][name] + \" \" + s, bottom=bottom, color=colors[s][name], width=bar_width)\n",
    "            # e = ax.errorbar(positions, x[i] + bottom, yerr=stds[s][name], fmt=errors[name]['fmt'], ecolor=errors[name]['ecolor'], linestyle=\"none\", transform=errors[name]['transform'])\n",
    "            if l == \"Enkhuizen\":\n",
    "                legends[legend[s][name] + \" \" + s] = p\n",
    "            bottom += x[i]\n",
    "\n",
    "\n",
    "ax.annotate(\"Enkhuizen hub\", xy=(0.4, 0), xytext=(-0.1, -0.033))\n",
    "ax.annotate(\"Heerlen hub\", xy=(0.4, 0), xytext=(1, -0.033))\n",
    "ax.annotate(\"Scenario\\nsize\", xy=(0, 0), xytext=(-0.6, -0.02), weight='bold')\n",
    "\n",
    "ax.annotate(\"@MAEDeR (left)\", xy=(0, means[\"@MAEDeR\"][\"Generation time\"][0][0]), xytext=(0, 0.05), arrowprops={'arrowstyle': '->', 'connectionstyle': 'arc3,rad=.5'})#width': 1, 'color': 'black', })\n",
    "ax.annotate(\"rSIPP (right)\", xy=(bar_width, means[\"rSIPP\"][\"Generation time\"][0][0]), xytext=(bar_width, 0.03), arrowprops={'arrowstyle': '->'})#width': 1, 'color': 'black', })\n",
    "\n",
    "ax.set_xticks([0.05, 0.3, 0.55, 1.05, 1.3, 1.55, 1.8])\n",
    "ax.set_xticklabels(list(labels.values())[0:-1] + list(labels.values()), rotation=45, ha='right')\n",
    "ax.xaxis.set_label_coords(0.6, -0.2)\n",
    "ax.minorticks_on()\n",
    "ax.xaxis.set_tick_params(which='minor', bottom=False)\n",
    "\n",
    "ax.set_ylabel(\"Time (s)\", rotation='horizontal', weight='bold')\n",
    "ax.yaxis.get_ticklocs(minor=True)\n",
    "ax.yaxis.set_label_coords(-0.1, 0.95)\n",
    "ax.set_ylim(0, max(newdf['GenTime'].mean() + newdf['SearchTime'].mean()) * 1.1)\n",
    "# ax.set_title(\"Average computation time @MAEDeR vs rSIPP\")\n",
    "ax.legend(legends.values(), legends.keys(), loc=(0, 0.68), ncol=1, frameon=False)\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.savefig(\"results/runtimes_dpi300.pdf\", \n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics on paths used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"results_enkhuizen+heerlen.csv\")\n",
    "nan = np.nan\n",
    "newdf = df.copy()\n",
    "pathdf = df.query('PathUsed != @nan').groupby(['Scenario', 'Layout', 'Start', 'Goal', 'Agent'])\n",
    "newdf['MinLengthPath'] = pathdf[['PathLength']].transform(min)\n",
    "newdf.head()\n",
    "\n",
    "path_occurence_average = newdf.query('PathUsed != @nan and PathLength == MinLengthPath')['PathOccurrence'].mean()\n",
    "print(f\"The shortest path was used in {path_occurence_average * 100}% of the cases\")\n",
    "\n",
    "# Prints a row for each path, but only in cases where more than one path was found\n",
    "pathdf = newdf.query('PathUsed != @nan and PathOccurrence < 1').groupby(['Scenario', 'Layout', 'Start', 'Goal', 'Agent'])[['Scenario', 'Layout', 'Agent', 'Start', 'Goal', 'PathLength', 'PathUsed', 'PathOccurrence', 'MinLengthPath']]\n",
    "pathdf.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
