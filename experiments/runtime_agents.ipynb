{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-06T15:29:34.051877Z",
     "start_time": "2025-07-06T15:29:32.759854Z"
    }
   },
   "source": [
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from copy import copy\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Disable logging of the program in the notebook\n",
    "os.environ[\"LOGLEVEL\"] = \"CRITICAL\"\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.root.setLevel(logging.INFO)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "logger = logging.getLogger('__main__')\n",
    "logger.setLevel(os.environ.get(\"LOGLEVEL\", logging.FATAL))\n",
    "\n",
    "pybooklogger = logging.getLogger('pybook')\n",
    "pybooklogger.setLevel(logging.DEBUG)\n",
    "\n",
    "%aimport setup\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from setup import *"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Track Layout\n",
    "Calculate the layout of the dutch railway system\n"
   ],
   "id": "10e60bbe9e78867a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T15:36:23.180902100Z",
     "start_time": "2025-07-06T15:35:52.190900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "layout_file =   \"../data/prorail/parsed/netherlands-schiphol.json\"\n",
    "layout = Layout(layout_file)"
   ],
   "id": "3fac23e191ae3",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m layout_file \u001B[38;5;241m=\u001B[39m   \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../data/prorail/parsed/netherlands-schiphol.json\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 2\u001B[0m layout \u001B[38;5;241m=\u001B[39m \u001B[43mLayout\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlayout_file\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Uni\\Thesis\\delay-replanning-slack\\experiments\\setup.py:115\u001B[0m, in \u001B[0;36mLayout.__init__\u001B[1;34m(self, layout)\u001B[0m\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, layout):\n\u001B[1;32m--> 115\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mg, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mg_block, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mg_duration, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mg_block_duration \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtime_graph_creation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlayout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Uni\\Thesis\\delay-replanning-slack\\generation\\generate.py:82\u001B[0m, in \u001B[0;36mtime_graph_creation\u001B[1;34m(location)\u001B[0m\n\u001B[0;32m     80\u001B[0m g_time \u001B[38;5;241m=\u001B[39m end_time \u001B[38;5;241m-\u001B[39m start_time\n\u001B[0;32m     81\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m---> 82\u001B[0m g_block \u001B[38;5;241m=\u001B[39m \u001B[43mblock_graph_constructor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     83\u001B[0m end_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m     84\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m g, g_block, g_time, end_time \u001B[38;5;241m-\u001B[39m start_time\n",
      "File \u001B[1;32m~\\Documents\\Uni\\Thesis\\delay-replanning-slack\\generation\\graph.py:340\u001B[0m, in \u001B[0;36mblock_graph_constructor\u001B[1;34m(g, use_pickle)\u001B[0m\n\u001B[0;32m    338\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mblock_graph_constructor\u001B[39m(g: TrackGraph, use_pickle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m    339\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m use_pickle:\n\u001B[1;32m--> 340\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mBlockGraph\u001B[49m\u001B[43m(\u001B[49m\u001B[43mg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    342\u001B[0m     last_modified \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mgetmtime(g\u001B[38;5;241m.\u001B[39mfile_name)\n\u001B[0;32m    343\u001B[0m     filename \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mg\u001B[38;5;241m.\u001B[39mfile_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m-\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlast_modified\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m-g_block.pkl\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32m~\\Documents\\Uni\\Thesis\\delay-replanning-slack\\generation\\graph.py:268\u001B[0m, in \u001B[0;36mBlockGraph.__init__\u001B[1;34m(self, g)\u001B[0m\n\u001B[0;32m    266\u001B[0m         direction \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mset\u001B[39m(signal\u001B[38;5;241m.\u001B[39mdirection \u001B[38;5;241m+\u001B[39m to_signal\u001B[38;5;241m.\u001B[39mdirection))\n\u001B[0;32m    267\u001B[0m         e \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd_edge(BlockEdge(from_signal_node, to_signal_node, length, block, direction, max_velocity))\n\u001B[1;32m--> 268\u001B[0m         logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound block \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m with length \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlength\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m and max velocity \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmax_velocity\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    269\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m station, track_nodes \u001B[38;5;129;01min\u001B[39;00m g\u001B[38;5;241m.\u001B[39mstations\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m    270\u001B[0m     node_a, node_b \u001B[38;5;241m=\u001B[39m track_nodes\n",
      "File \u001B[1;32m~\\Documents\\Uni\\Thesis\\delay-replanning-slack\\generation\\graph.py:146\u001B[0m, in \u001B[0;36mEdge.__str__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    145\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__str__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 146\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfrom_node\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m--\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mto_node\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "edges_df = pd.DataFrame({\"Outgoing routes\": [len(n.outgoing) for n in layout.g_block.nodes.values() if len(n.outgoing) <= 25]})\n",
    "hist = edges_df.hist(bins=25, )\n",
    "plt.xlabel(\"Number of outgoing routes\")\n",
    "plt.ylabel(\"Number of occurrences\")\n",
    "plt.show()"
   ],
   "id": "b449610276d9ed50",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Experiment Runtime Agents\n",
   "id": "f790d43ecde3747"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "scenario_file = \"../data/prorail/scenarios/RT/2025-07-04_1.json\"\n",
    "exp_settings = {\n",
    "    \"origin\": \"RTD|9\", \n",
    "    \"destination\": \"ASDZ|2\",\n",
    "    \"start_time\": 900,\n",
    "    \"max_buffer_time\": 900,\n",
    "    \"use_recovery_time\": True,\n",
    "}\n",
    "set_default(exp_settings)\n",
    "experiments = []\n",
    "try:\n",
    "    base_path = Path(__file__).parent\n",
    "    file_path = (base_path / scenario_file).resolve()\n",
    "    data = json.load(open(file_path))\n",
    "except:\n",
    "    data = json.load(open(scenario_file))\n",
    "pybooklogger.setLevel(logging.INFO)\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "for idx, entry in enumerate(data[\"trains\"]):\n",
    "    scenario_data = copy(data)\n",
    "    scenario_data[\"trains\"] = data[\"trains\"][:idx+1]\n",
    "    with open(\"temp_scenario.json\", \"w\") as outfile:\n",
    "        json.dump(scenario_data, outfile)\n",
    "    scenario = Scenario(layout, \"temp_scenario.json\", -1)\n",
    "    origin = exp_settings[\"origin\"]\n",
    "    destination = exp_settings[\"destination\"]\n",
    "    velocity = exp_settings[\"velocity\"]\n",
    "    start_time = exp_settings[\"start_time\"]\n",
    "    max_buffer_time = exp_settings[\"max_buffer_time\"]\n",
    "    use_recovery_time = exp_settings[\"use_recovery_time\"]\n",
    "    metadata = exp_settings[\"metadata\"]\n",
    "    metadata[\"label\"] = f\"Num trains: {idx + 1}\"\n",
    "\n",
    "    agent_id = scenario.agent_id\n",
    "    pybooklogger.info(f\"Setting up experiment {exp_settings}\")\n",
    "\n",
    "    origin_signal = scenario.l.station_to_block(origin, direction=1)\n",
    "    destination_signal = scenario.l.station_to_block(destination, direction=1)\n",
    "    agent = Agent(agent_id, origin_signal, destination_signal, velocity, start_time)\n",
    "\n",
    "    experiments.append(Experiment(scenario, agent, max_buffer_time, use_recovery_time, metadata))\n"
   ],
   "id": "7d8e2103b47182f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Blocking staircase diagram\n",
    "Showing the route of the agent with the most stops, its quite long.\n"
   ],
   "id": "c086af2cdb38f7e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "exp = experiments[-1]\n",
    "exp.s.plot(-1, exp.buffer_times, exp.recovery_times, False)"
   ],
   "id": "8c1362474f1582be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "timeout = 7200\n",
    "run_experiments(experiments, timeout)"
   ],
   "id": "4d50e56830c416d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Results\n",
   "id": "a06921c86e58dbc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Time statistics",
   "id": "c5d344d88e29c4bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sum_cols(df1, cols, name):\n",
    "    df2 = df1.drop(columns=cols)\n",
    "    df2[name] = df1[cols].sum(axis=1)\n",
    "    return df2\n",
    "\n",
    "time_df = pd.DataFrame([exp.get_running_time() for exp in experiments], index=[exp.metadata['label'] for exp in experiments])\n",
    "\n",
    "setup_cols = [\"track graph creation\", \"routing graph creation\"]\n",
    "recompute_cols = [\"unsafe interval generation\", \"safe interval generation\", \"bt and crt generation\", \"converting routes to blocks\"]\n",
    "search_cols = [\"FlexSIPP search time\"]\n",
    "\n",
    "time_df = sum_cols(time_df, setup_cols, \"Setup Time\")\n",
    "time_df = sum_cols(time_df, recompute_cols, \"Recompute Time\")\n",
    "time_df = sum_cols(time_df, search_cols, \"Search Time\")\n",
    "time_df"
   ],
   "id": "e608f77d8785d47c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "f79b767975fef06e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Search Node Statistics\n",
   "id": "1142aae3c2986a98"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nodes_df = pd.DataFrame([exp.get_complexity() for exp in experiments], index=[exp.metadata['label'] for exp in experiments])\n",
    "\n",
    "nodes_df"
   ],
   "id": "47a57c7bdc689a2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Output paths found\n",
   "id": "5a25d5efbeb35507"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for key, value in experiments[2].results[3].items():\n",
    "    delayed_trains = {i: v for i,v in enumerate(value[0][4]) if float(v[0]) > 0}\n",
    "    print(f\"{key.replace('r-', '')}\\nearliest departure: {int(min(float(value[0][1]), float(value[0][2])) / 60)}\\ndepart before: {int(float(value[0][2]) / 60)}\\narrive at: {int((float(value[0][1]) + float(value[0][3])) / 60)}\\ndelays trains: {delayed_trains}\")"
   ],
   "id": "e95ea61f1dda3c51",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Path statistics\n",
   "id": "55f8dc6e386227ab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for exp in experiments:\n",
    "    print(f\"Differend paths found for {exp.metadata['label']}: {sum(exp.results[2].values())}\")"
   ],
   "id": "310d8cb8de6d492e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
