{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Disable logging of the program in the notebook\n",
    "os.environ[\"LOGLEVEL\"] = \"CRITICAL\"\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.root.setLevel(logging.INFO)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "logger = logging.getLogger('__main__')\n",
    "logger.setLevel(os.environ.get(\"LOGLEVEL\", logging.FATAL))\n",
    "\n",
    "pybooklogger = logging.getLogger('pybook')\n",
    "pybooklogger.setLevel(logging.DEBUG)\n",
    "\n",
    "%aimport setup\n",
    "\n",
    "from setup import *"
   ],
   "id": "6b5fe0a9d06af370"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Track Layout\n",
    "Calculate the layout of the dutch railway system\n"
   ],
   "id": "c7e18bbb5615b3e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "layout_file =   \"../data/prorail/parsed/netherlands-schiphol.json\"\n",
    "layout = Layout(layout_file)"
   ],
   "id": "1aa0383ab82b146d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "edges_df = pd.DataFrame({\"Outgoing routes\": [len(n.outgoing) for n in layout.g_block.nodes.values() if len(n.outgoing) <= 25]})\n",
    "hist = edges_df.hist(bins=25, )\n",
    "plt.xlabel(\"Number of outgoing routes\")\n",
    "plt.ylabel(\"Number of occurrences\")\n",
    "plt.show()"
   ],
   "id": "54ebce1a668c6655"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Experiment Runtime Agents\n",
   "id": "ad07a8eff947af2c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "scenario_file = \"../data/prorail/scenarios/RT/2025-07-04_1.json\"\n",
    "agents = []\n",
    "try:\n",
    "    base_path = Path(__file__).parent\n",
    "    file_path = (base_path / scenario_file).resolve()\n",
    "    data = json.load(open(file_path))\n",
    "except:\n",
    "    data = json.load(open(scenario_file))\n",
    "\n",
    "types = {x[\"name\"]: x for x in data[\"types\"]}\n",
    "for trainNumber, entry in enumerate(data[\"trains\"]):\n",
    "    trainNumber += 1\n",
    "    move = entry[\"movements\"][0]\n",
    "    velocity = types[entry[\"trainUnitTypes\"][0]][\"speed\"] / 3.6\n",
    "\n",
    "    agent = Agent(trainNumber, move[\"startLocation\"], move[\"endLocation\"], velocity, move[\"startTime\"],\n",
    "                  endTime=move[\"endTime\"],\n",
    "                  startTimeHuman=str(timedelta(seconds=move[\"startTime\"])),\n",
    "                  endTimeHuman=str(timedelta(seconds=move[\"endTime\"])),\n",
    "                  trainNumber=entry[\"trainNumber\"],\n",
    "                  trainUnitTypes=entry[\"trainUnitTypes\"],\n",
    "                  stops=move[\"stops\"],\n",
    "    )\n",
    "    agents.append(agent)\n",
    "agent_df = pd.DataFrame([agent.__dict__ for agent in agents])\n",
    "series_3500o = agent_df.loc[(agent_df['trainNumber'].str.startswith(\"35\", na=False)) & (agent_df['trainNumber'].astype(int) % 2 == 1)].sort_values(\"start_time\")\n",
    "agent_df"
   ],
   "id": "bcba01c136bb3bfe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "longest = series_3500o.loc[series_3500o['stops'].map(len).idxmax()]\n",
    "\n",
    "# This train would be at 2700 at GV|6, we will be replanning its path till ASDZ|2\n",
    "longest"
   ],
   "id": "4de4b8bf7d30f28b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "stops_df = pd.DataFrame(longest[\"stops\"])\n",
    "r_rtd = stops_df.loc[stops_df[\"location\"].str.contains(\"RTD\", na=False)]\n",
    "r_asdz = stops_df.loc[stops_df[\"location\"].str.contains(\"ASDZ\", na=False)]\n",
    "\n",
    "i_rtd = r_rtd.index[0] + 1\n",
    "i_asdz = r_asdz.index[0]\n",
    "stops = longest[\"stops\"][i_rtd:i_asdz]\n",
    "\n",
    "print(f\"i_rtd={i_rtd}, i_asdz={i_asdz}\")\n",
    "print(f\"stops={stops}\")\n",
    "\n",
    "move = {\n",
    "    \"endLocation\": r_asdz[\"location\"].iloc[0],\n",
    "    \"endTime\": r_asdz[\"expected_arrival\"].iloc[0],\n",
    "    \"startLocation\": r_rtd[\"location\"].iloc[0],\n",
    "    \"startTime\": r_rtd[\"time\"].iloc[0],\n",
    "    \"stops\": stops,\n",
    "}\n",
    "\n",
    "block_path = layout.get_path_for_agent(move, longest[\"trainNumber\"], longest[\"velocity\"])\n",
    "\n",
    "def filter_origin(n):\n",
    "    return n.split(\"-\")[1].split(\"|\")[0]\n",
    "\n",
    "allowed_nodes = {filter_origin(block_path[0].from_node.name)}\n",
    "for e in block_path:\n",
    "    allowed_nodes.add(filter_origin(e.to_node.name))\n",
    "allowed_nodes"
   ],
   "id": "b4d915c3632a4fe9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "exp_settings = {\n",
    "    \"origin\": r_rtd[\"location\"].iloc[0],\n",
    "    \"destination\": r_asdz[\"location\"].iloc[0],\n",
    "    \"start_time\": r_rtd[\"time\"].iloc[0],\n",
    "    \"max_buffer_time\": 900,\n",
    "    \"use_recovery_time\": True,\n",
    "    \"filter_agents\": longest[\"id\"],\n",
    "    \"metadata\": {\n",
    "        \"expected_arrival\": r_asdz[\"expected_arrival\"].iloc[0],\n",
    "    }\n",
    "}\n",
    "set_default(exp_settings)\n",
    "exp_settings"
   ],
   "id": "edd748173c39ab7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "scenario = Scenario(layout, scenario_file)",
   "id": "90fd8d91f606c598"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "np.random.seed(42)\n",
    "interval = 1\n",
    "repeats = 1\n",
    "\n",
    "n_trains = len(data[\"trains\"]) + 1\n",
    "\n",
    "timeout = 600\n",
    "\n",
    "time_data = []\n",
    "complexity_data = []\n",
    "path_data = []\n",
    "metadatas = []\n",
    "\n",
    "for repeat in range(repeats):\n",
    "    train_ids = np.arange(1, n_trains)\n",
    "    train_ids = train_ids[train_ids != longest[\"id\"]]\n",
    "    shuffled_ids = np.random.permutation(train_ids)\n",
    "    for idx in range(0, n_trains, interval):\n",
    "        filter_agents = set(shuffled_ids[:idx])\n",
    "        filter_agents.add(longest[\"id\"])\n",
    "\n",
    "        origin = exp_settings[\"origin\"]\n",
    "        destination = exp_settings[\"destination\"]\n",
    "        velocity = exp_settings[\"velocity\"]\n",
    "        start_time = exp_settings[\"start_time\"]\n",
    "        max_buffer_time = exp_settings[\"max_buffer_time\"]\n",
    "        use_recovery_time = exp_settings[\"use_recovery_time\"]\n",
    "        metadata = deepcopy(exp_settings[\"metadata\"])\n",
    "        metadata[\"label\"] = f\"{idx}\"\n",
    "        metadata[\"repeat\"] = f\"{idx}\"\n",
    "        metadata[\"trains excluded\"] = filter_agents\n",
    "        exp_settings[\"metadata\"] = metadata\n",
    "        metadatas.append(metadata)\n",
    "\n",
    "        pybooklogger.info(f\"Setting up experiment {exp_settings}\\n Trains excluded: {filter_agents}\")\n",
    "\n",
    "        origin_signal = scenario.l.station_to_block(origin, direction=1)\n",
    "        destination_signal = scenario.l.station_to_block(destination, direction=1)\n",
    "        agent = Agent(longest[\"id\"], origin_signal, destination_signal, velocity, start_time)\n",
    "\n",
    "        exp = Experiment(scenario, agent, filter_agents, max_buffer_time, use_recovery_time, metadata)\n",
    "\n",
    "        exp.run_search(timeout, filter_tracks=allowed_nodes)\n",
    "\n",
    "        time_data.append(exp.get_running_time() | exp.get_label())\n",
    "        complexity_data.append(exp.get_complexity() | exp.get_label())\n",
    "        path_data.append({\"number of paths\": sum(exp.results[2].values())} | exp.get_label())\n"
   ],
   "id": "be506517bfa62c02"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Blocking staircase diagram\n",
    "Showing the route of the agent with the most stops, its quite long.\n"
   ],
   "id": "7728e55acf2afced"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "exp.s.plot(longest[\"id\"], exp.block_intervals, exp.buffer_times, exp.recovery_times, False)",
   "id": "ce69bfd0e5ee9b7d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Results\n",
   "id": "e6c85d941a5c1d2c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from datetime import date\n",
    "save_dir = r\"C:\\Users\\erick\\Documents\\uni\\Thesis\\delay-replannning\\experiments\\results\\runtime_agents\""
   ],
   "id": "bc366821ed2a4b00"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Time statistics",
   "id": "d0dcd9de9303e6fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def sum_cols(df1, cols, name):\n",
    "    df2 = df1.drop(columns=cols)\n",
    "    df2[name] = df1[cols].sum(axis=1)\n",
    "    return df2\n",
    "\n",
    "time_df = pd.DataFrame(time_data)\n",
    "\n",
    "time_df.to_csv(f\"{save_dir}\\\\time_df-r{repeats}-i{interval}-{date.today()}.csv\", index=False)\n",
    "\n",
    "time_df[\"Number of agents\"] = pd.to_numeric(time_df[\"label\"])\n",
    "\n",
    "setup_cols = [\"track graph creation\", \"routing graph creation\"]\n",
    "recompute_cols = [\"unsafe interval generation\", \"safe interval generation\", \"bt and crt generation\", \"converting routes to blocks\"]\n",
    "search_cols = [\"FlexSIPP search time\"]\n",
    "\n",
    "time_df = sum_cols(time_df, setup_cols, \"Setup Time\")\n",
    "time_df = sum_cols(time_df, recompute_cols, \"Recompute Time\")\n",
    "time_df = sum_cols(time_df, search_cols, \"Search Time\")\n",
    "\n",
    "time_mean_std = (\n",
    "    time_df.groupby([\"Number of agents\"]).agg({\"Search Time\":[\"mean\", \"std\"]})\n",
    "    .set_axis([\"mean\", \"std\"], axis=1)\n",
    "    .reset_index()\n",
    "    [[\"mean\", \"std\"]]\n",
    ")\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "time_mean_std.plot(ax=ax, yerr=\"std\", errorevery=5, legend=False)\n",
    "# time_df.loc[time_df[\"Search Time\"] > -1][\"Search Time\"].plot()\n",
    "plt.ylabel(\"Search Time (s)\")\n",
    "plt.xlabel(\"Number of agents excluded\")\n",
    "plt.title(\"Run time of FlexSIPP\")\n",
    "\n",
    "plt.savefig(f\"{save_dir}\\\\time_df-{date.today()}.png\")\n",
    "\n",
    "# time_df.plot(ax=ax, x=\"Number of agents\", y=\"Search Time\", kind=\"scatter\", s=1)\n",
    "time_mean_std"
   ],
   "id": "b38e251bec28d0b7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Search Node Statistics\n",
   "id": "7a5f3a5b8444873b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "nodes_df = pd.DataFrame(complexity_data)\n",
    "\n",
    "nodes_df.to_csv(f\"{save_dir}\\\\nodes_df-r{repeats}-i{interval}-{date.today()}.csv\", index=False)\n",
    "\n",
    "nodes_df[\"Agents excluded\"] = pd.to_numeric(nodes_df[\"label\"])\n",
    "nodes_df = nodes_df.groupby(\"Agents excluded\").mean()\n",
    "nodes_df.plot()\n",
    "plt.savefig(f\"{save_dir}\\\\nodes_df-{date.today()}.png\")"
   ],
   "id": "40646d5f16059a5f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Output paths found\n",
   "id": "3802843f459fec19"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# for key, value in experiments[-1].results[3].items():\n",
    "#     delayed_trains = {i: v for i,v in enumerate(value[0][4]) if float(v[0]) > 0}\n",
    "#     print(f\"{key.replace('r-', '')}\\nearliest departure: {int(min(float(value[0][1]), float(value[0][2])) / 60)}\\ndepart before: {int(float(value[0][2]) / 60)}\\narrive at: {int((float(value[0][1]) + float(value[0][3])) / 60)}\\ndelays trains: {delayed_trains}\")"
   ],
   "id": "7f8269fee1293f25"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Path statistics\n",
   "id": "b1317a0cd606553f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "num_paths_df = pd.DataFrame(path_data)\n",
    "\n",
    "num_paths_df.to_csv(f\"{save_dir}\\\\num_paths_df-r{repeats}-i{interval}-{date.today()}.csv\", index=False)\n",
    "num_paths_df[\"Agents excluded\"] = pd.to_numeric(num_paths_df[\"label\"])\n",
    "num_paths_df = num_paths_df.groupby(\"Agents excluded\").mean()\n",
    "\n",
    "num_paths_df.plot()\n",
    "plt.savefig(f\"{save_dir}\\\\num_paths_df-{date.today()}.png\")"
   ],
   "id": "b7e76a28c9ae3b80"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
